# -*- coding: utf-8 -*-
"""ZacheryMoyDSPT3Project 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kjpC7X_vKCTxyRLG0Z2mjfP8eeyde_IY

## Install Packages
"""

!pip install category_encoders==2.*
!pip install eli5

!pip install chart_studio
import chart_studio.plotly as py
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import category_encoders as ce
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline
from xgboost import XGBClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn import svm, datasets
svc = svm.SVC()
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import confusion_matrix
import seaborn as sns
import eli5
from eli5.sklearn import PermutationImportance
from sklearn.metrics import accuracy_score
!pip install shap
from sklearn.linear_model import LogisticRegressionCV
import shap
!pip install PDPbox
from pdpbox import pdp, get_dataset, info_plots

"""## Upload Dataset and Clean"""

df = pd.read_excel (r'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls') 
df.head()

# Dropping header 

header = df.iloc[0]
df = df[1:]

df = df.rename(columns = header)

df.head()

# Convert Target to Integer
df['default payment next month'] = df['default payment next month'].astype(int)

df['default payment next month'].unique()

df['default payment next month'].describe()

df.shape

# Attribute Information:

# This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:
# X1 (Limit Balance=Continous): Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.
# X2: (Discrete/Binary) Gender (1 = male; 2 = female).
# X3: (Discrete/Binary) Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).
# X4: (Discrete/Binary) Marital status (1 = married; 2 = single; 3 = others).
# X5: (Continous) Age (year).
# X6 - X11 (Pay 0): (Discrete) History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; 
#. . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay (??); 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.
# X12-X17: (Continous) Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.
# X18-X23: (Continuous) Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.?

# Create new features? 

# X12-X17 = People eventually give up after bill statement piles up. 
# X18-X23 = Same as above
# X6-X11 = Do some people eventually give up? 
# X4 = Are married people more likely to pay? 
# X3 = High school student behavior, who's more likely to pay? 
# X5 = Age correlated to payment? 
# What is the best predictor given my parameters?

df.AGE.hist()

df.SEX.hist()

"""## Figuring out issues with data not loading early on"""

# y_train.dtype
# y_test.isnull().sum()
# y_test.dtype
# y_train.isnull().sum()
# No nulls 
# X_train.isnull().sum()

"""## Train, Validate, Test Split"""

train, test = train_test_split(df, test_size=0.1, random_state=42)

df.shape, test.shape, train.shape

train, val = train_test_split(train, random_state=42)
train.shape, val.shape, test.shape

train['default payment next month']

# baseline 
target = 'default payment next month'
y_train = train[target]
y_train.value_counts(normalize=True)

majority_class = y_train.mode()[0]
y_pred = [majority_class] * len(y_train)

y_train.unique()

accuracy_score(y_train, y_pred)

# Arrange data into X features matrix and y target vector
X_train = train.drop(columns=target)
#y_train = train[target]
X_val = val.drop(columns=target)
y_val = val[target]
X_test = test.drop(columns=target)
y_test = test[target]

X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape

y_train.describe().T

"""##Pipeline 1"""

X_train.describe().T

y_train = y_train.astype(int)

features = ['MARRIAGE']

pipe = make_pipeline (
    ce.OrdinalEncoder(),
    RandomForestClassifier(
        n_estimators=100,
        class_weight='balanced',
        n_jobs=-1,
    )
)

cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc')

# Compute the confusion_matrix
confusion_matrix(y_train, y_pred)

# Get the unique labels

unique_labels(y_train)

def plot_confusion_matrix(y_true, y_pred):
  labels = unique_labels(y_true)
  columns = [f'Predicted {label}' for label in labels]
  index = [f'Actual {label}' for label in labels]
  df = pd.DataFrame(confusion_matrix(y_true, y_pred),
                    columns = columns,
                    index = index)
  return sns.heatmap(df, annot=True, fmt='d', cmap='Blues')

plot_confusion_matrix(y_train, y_pred);

# This now shows binary integers
y_train.unique()

"""## Pipeline 2: Fitting XGClassifier"""

pipeline = make_pipeline(
    ce.OrdinalEncoder(),
    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)
)

# Fit on train, score on val
pipeline.fit(X_train, y_train)

pipeline.score(X_train, y_train)
# Remember this is my baseline: 0    0.775951

print('Validation Accuracy', pipeline.score(X_val, y_val))

print('Test Accuracy', pipeline.score(X_test, y_test))

processor1 = make_pipeline(
    ce.OrdinalEncoder(), 
    SimpleImputer(strategy='median')
)

X_train_processed = processor1.fit_transform(X_train)
X_val_processed = processor1.transform(X_val)

eval_set = [(X_train_processed, y_train), 
            (X_val_processed, y_val)]

model1 = XGBClassifier(n_estimators=1000, n_jobs=-1)
model1.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', 
          early_stopping_rounds=10)

row = X_test.iloc[[3]]
explainer=shap.TreeExplainer(model1)
row_processed = processor1.transform(row)
shap_values = explainer.shap_values(row_processed)

shap.initjs()
shap.force_plot(
    base_value=explainer.expected_value,
    shap_values=shap_values,
    features=row,
    link='logit'               # For classification, this returns predicted probs
)

permuter = PermutationImportance(
    model1,
    scoring='accuracy',
    n_iter=5,
    random_state=42
)
permuter.fit(X_val_processed, y_val)

permuter.feature_importances_

eli5.show_weights(
    permuter,
    top=None,
    feature_names=X_val.columns.tolist()
)

"""## Logistic Regression Model for Classification: Models 3 and 4"""

# 3rd Model
logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)

print('Validation Accuracy', logmodel.score(X_val, y_val))
# Remember this is my baseline: 0    0.775951

print('Test Accuracy', logmodel.score(X_test, y_test))
# Remember this is my baseline: 0    0.775951

# 4th Model

imputer = SimpleImputer()
X_train_imputed = imputer.fit_transform(X_train)
X_val_imputed = imputer.transform(X_val)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_val_scaled = scaler.transform(X_val_imputed)

model2 = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)
model2.fit(X_train_scaled, y_train)
print('Validation Accuracy', model2.score(X_val_scaled, y_val))

X_test_imputed = imputer.transform(X_test)
X_test_scaled = scaler.transform(X_test_imputed)
print('Test Accuracy', model2.score(X_test_scaled, y_test))

model2.intercept_, model2.coef_

"""## Dash app?"""

!pip install dash==1.0.2
!pip install dash-daq==0.1.0

import dash
import dash_core_components as dcc
import dash_html_components as html